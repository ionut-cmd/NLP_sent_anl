# EX 1
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.KLDivLoss(reduction='batchmean)

prediction= sadness

auc = {0: 0.7656497749271673, 1: 0.8282708561201153, 2: 0.81796061839417, 3: 0.7824085110537442, 4: 0.8761141786869693, 5: 0.7520778652668417, 6: 0.8095874906001195, 7: 0.7193166264554031, 8: 0.8082916074741688, 9: 0.852444046262268, 10: 0.7442467920548427, 11: 0.8426733986646018, 12: 0.8799602584466623, 13: 0.7230767119527927}

cm = [[ 124    8    8   34   32    0   37    6    2   11    3    5   11  330]
 [  19   10    5    4    2    0    7    1    1    0    0    0    1   39]
 [   7    6   18    8    3    0    8    3    1    0    1    2    0   31]
 [  17    3    0  351  129    0   21   18    9    2    0    8   19  289]
 [  11    4    1   77  546    0   21   14   11    8    0    2    9  135]
 [   3    0    0    3    6    2    2    1    0    0    0    0    1    6]
 [  31    5    9   17   24    0  158   12    8    7    2    3    7  155]
 [  15    1    6   28   32    0   23   56    3    2    0    2    9  169]
 [   4    0    1   21   47    0    6    1   71    0    0    9    1   73]
 [   8    0    1   10    4    0    9    7    0   32    0    0   32   74]
 [   6    2    0    2    5    0   14    4    1    0    3    0    1   12]
 [   3    0    0   12   17    0    2    0    8    1    0   31    4   34]
 [   6    0    1   24   14    0    6    3    4   22    0    1  107  102]
 [  60    4   14  118  124    0   57   19   16   23    0   20   61 1059]]





